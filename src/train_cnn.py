import os
import pandas as pd
import numpy as np
import librosa
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import ModelCheckpoint

def extract_mfcc(file_path, n_mfcc=40):
    try:
        audio, sample_rate = librosa.load(file_path, sr=16000, res_type='kaiser_fast')
        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)
        return np.mean(mfccs.T, axis=0)
    except Exception as e:
        return None

def train_model():
    print("ğŸ” Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (clean_metadata.csv)...")
    csv_path = "./dataset/clean_metadata.csv"
    
    if not os.path.exists(csv_path):
        print("âŒ Ù…Ù„Ù clean_metadata.csv ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
        return

    df = pd.read_csv(csv_path)
    
    # --- Ø§Ù„ÙÙ‡Ø±Ø³Ø© Ø§Ù„Ø°ÙƒÙŠØ© (Ø¨ÙˆÙ†ØªÙˆ ÙÙŠ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© ÙˆØ§Ù„ØµØºÙŠØ±Ø©) ---
    print("ğŸš€ Ø¬Ø§Ø±ÙŠ Ù…Ø³Ø­ Ù…Ø¬Ù„Ø¯ dataset Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØª...")
    wav_dict = {}
    for root, dirs, files in os.walk(os.path.abspath("./dataset")):
        for file in files:
            # Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø³Ø­Ø±ÙŠØ©: Ù†Ø±Ø¯ÙˆÙ‡Ø§ lower() Ø¨Ø§Ø´ ÙŠÙ‚Ø¨Ù„ .wav Ùˆ .WAV
            if file.lower().endswith(".wav"): 
                wav_dict[file.lower()] = os.path.join(root, file)
                
    print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(wav_dict)} Ù…Ù„Ù ØµÙˆØªÙŠ Ø¥Ø¬Ù…Ø§Ù„Ø§Ù‹ ÙÙŠ Ø§Ù„Ø¬Ù‡Ø§Ø².")

    X, y = [], []
    missing_files = 0

    print("ğŸ§ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØªÙŠØ©... (Ù‡Ø°Ø§ Ø³ÙŠØ³ØªØºØ±Ù‚ Ø¨Ø¹Ø¶ Ø§Ù„ÙˆÙ‚Øª)")
    
    for index, row in df.iterrows():
        # Ù†Ø§Ø®Ø°Ùˆ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù ÙˆÙ†Ø±Ø¯ÙˆÙ‡ Ø­Ø±ÙˆÙ ØµØºÙŠØ±Ø© Ø¨Ø§Ø´ ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ø§Ù„ÙÙ‡Ø±Ø³
        filename = os.path.basename(row['wav_path']).lower()
        
        real_wav_path = wav_dict.get(filename)
        
        if real_wav_path is None:
            missing_files += 1
            continue
            
        features = extract_mfcc(real_wav_path)
        if features is not None:
            X.append(features)
            normalized_score = (row['score'] / 10.0) * 100
            y.append(normalized_score)
            
        if len(X) % 500 == 0 and len(X) > 0:
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© {len(X)} Ù…Ù„Ù ØµÙˆØªÙŠ...")

    print(f"â„¹ï¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©: ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© {len(X)} Ù…Ù„Ù. Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©: {missing_files}")
    
    if len(X) == 0:
        print("ğŸš¨ Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙŠ Ù…Ù„Ù. ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙÙƒÙˆÙƒ Ø¶ØºØ·Ù‡Ø§ Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ dataset.")
        return

    X = np.array(X)
    y = np.array(y)
    X = X.reshape(X.shape[0], X.shape[1], 1)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    print("ğŸ§  Ø¬Ø§Ø±ÙŠ Ø¨Ù†Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù€ CNN...")
    model = Sequential([
        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(40, 1)),
        MaxPooling1D(pool_size=2),
        Dropout(0.2),
        Conv1D(filters=128, kernel_size=3, activation='relu'),
        MaxPooling1D(pool_size=2),
        Dropout(0.2),
        Flatten(),
        Dense(64, activation='relu'),
        Dense(1, activation='linear')
    ])

    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    checkpoint = ModelCheckpoint('dataset/speech_cnn_model.h5', monitor='val_loss', save_best_only=True, verbose=1)

    history = model.fit(
        X_train, y_train,
        epochs=30, 
        batch_size=32,
        validation_data=(X_test, y_test),
        callbacks=[checkpoint]
    )
    print("ğŸ‰ Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨! ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ ÙÙŠ: dataset/speech_cnn_model.h5")

if __name__ == "__main__":
    train_model()